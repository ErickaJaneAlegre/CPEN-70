{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErickaJaneAlegre/CPEN-70/blob/main/CHAPTER_11_LAB_EXERCISE_8_part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S_KGcfffy4n"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZ9LpgMRfy4p"
      },
      "outputs": [],
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 1.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deep\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Mn1fGEVwfy7b"
      },
      "source": [
        "## 9. Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug01RD9rfy7b"
      },
      "source": [
        "a. Create a new DNN that reuses all the pretrained hidden layers of the previous model, freezes them, and replaces the softmax output layer with a new one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV53zPeFfy7d"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "restore_saver = tf.train.import_meta_graph(\"./my_best_mnist_model_0_to_4.meta\")\n",
        "\n",
        "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
        "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
        "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
        "Y_proba = tf.get_default_graph().get_tensor_by_name(\"Y_proba:0\")\n",
        "logits = Y_proba.op.inputs[0]\n",
        "accuracy = tf.get_default_graph().get_tensor_by_name(\"accuracy:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KO6DQTSqfy7e"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"logits\")\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
        "training_op = optimizer.minimize(loss, var_list=output_layer_vars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWm_Tla5fy7f"
      },
      "outputs": [],
      "source": [
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "five_frozen_saver = tf.train.Saver()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnNAkPByfy7f"
      },
      "source": [
        "b.\tTrain this new DNN on digits 5 to 9, using only 100 images per digit, and time how long it takes. Despite this small number of examples, can you achieve high precision?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1DlOfbffy7g"
      },
      "outputs": [],
      "source": [
        "X_train2_full = X_train[y_train >= 5]\n",
        "y_train2_full = y_train[y_train >= 5] - 5\n",
        "X_valid2_full = X_valid[y_valid >= 5]\n",
        "y_valid2_full = y_valid[y_valid >= 5] - 5\n",
        "X_test2 = X_test[y_test >= 5]\n",
        "y_test2 = y_test[y_test >= 5] - 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WBOZPZ5fy7h"
      },
      "outputs": [],
      "source": [
        "def sample_n_instances_per_class(X, y, n=100):\n",
        "    Xs, ys = [], []\n",
        "    for label in np.unique(y):\n",
        "        idx = (y == label)\n",
        "        Xc = X[idx][:n]\n",
        "        yc = y[idx][:n]\n",
        "        Xs.append(Xc)\n",
        "        ys.append(yc)\n",
        "    return np.concatenate(Xs), np.concatenate(ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTilh60Afy7h"
      },
      "outputs": [],
      "source": [
        "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
        "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb4LibPQfy7i",
        "outputId": "cd8e7140-3391-4936-c6e0-decb29b22360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./my_best_mnist_model_0_to_4\n",
            "0\tValidation loss: 1.361167\tBest loss: 1.361167\tAccuracy: 43.33%\n",
            "1\tValidation loss: 1.154602\tBest loss: 1.154602\tAccuracy: 57.33%\n",
            "2\tValidation loss: 1.054218\tBest loss: 1.054218\tAccuracy: 53.33%\n",
            "3\tValidation loss: 0.981128\tBest loss: 0.981128\tAccuracy: 62.67%\n",
            "4\tValidation loss: 0.995353\tBest loss: 0.981128\tAccuracy: 59.33%\n",
            "5\tValidation loss: 0.967000\tBest loss: 0.967000\tAccuracy: 65.33%\n",
            "6\tValidation loss: 0.955700\tBest loss: 0.955700\tAccuracy: 61.33%\n",
            "7\tValidation loss: 1.015331\tBest loss: 0.955700\tAccuracy: 58.67%\n",
            "8\tValidation loss: 0.978280\tBest loss: 0.955700\tAccuracy: 62.00%\n",
            "9\tValidation loss: 0.923389\tBest loss: 0.923389\tAccuracy: 69.33%\n",
            "10\tValidation loss: 0.996236\tBest loss: 0.923389\tAccuracy: 63.33%\n",
            "11\tValidation loss: 0.976757\tBest loss: 0.923389\tAccuracy: 62.67%\n",
            "12\tValidation loss: 0.969096\tBest loss: 0.923389\tAccuracy: 63.33%\n",
            "13\tValidation loss: 1.023069\tBest loss: 0.923389\tAccuracy: 63.33%\n",
            "14\tValidation loss: 1.104664\tBest loss: 0.923389\tAccuracy: 55.33%\n",
            "15\tValidation loss: 0.950175\tBest loss: 0.923389\tAccuracy: 65.33%\n",
            "16\tValidation loss: 1.002944\tBest loss: 0.923389\tAccuracy: 63.33%\n",
            "17\tValidation loss: 0.895543\tBest loss: 0.895543\tAccuracy: 70.67%\n",
            "18\tValidation loss: 0.961151\tBest loss: 0.895543\tAccuracy: 66.67%\n",
            "19\tValidation loss: 0.896372\tBest loss: 0.895543\tAccuracy: 67.33%\n",
            "20\tValidation loss: 0.911938\tBest loss: 0.895543\tAccuracy: 69.33%\n",
            "21\tValidation loss: 0.929007\tBest loss: 0.895543\tAccuracy: 68.00%\n",
            "22\tValidation loss: 0.939231\tBest loss: 0.895543\tAccuracy: 65.33%\n",
            "23\tValidation loss: 0.919057\tBest loss: 0.895543\tAccuracy: 68.67%\n",
            "24\tValidation loss: 0.994529\tBest loss: 0.895543\tAccuracy: 65.33%\n",
            "25\tValidation loss: 0.901279\tBest loss: 0.895543\tAccuracy: 68.67%\n",
            "26\tValidation loss: 0.916238\tBest loss: 0.895543\tAccuracy: 68.67%\n",
            "27\tValidation loss: 1.007434\tBest loss: 0.895543\tAccuracy: 65.33%\n",
            "28\tValidation loss: 0.924729\tBest loss: 0.895543\tAccuracy: 70.00%\n",
            "29\tValidation loss: 0.974399\tBest loss: 0.895543\tAccuracy: 66.00%\n",
            "30\tValidation loss: 0.899418\tBest loss: 0.895543\tAccuracy: 68.00%\n",
            "31\tValidation loss: 0.940563\tBest loss: 0.895543\tAccuracy: 66.00%\n",
            "32\tValidation loss: 0.920235\tBest loss: 0.895543\tAccuracy: 68.00%\n",
            "33\tValidation loss: 0.929848\tBest loss: 0.895543\tAccuracy: 68.67%\n",
            "34\tValidation loss: 0.930288\tBest loss: 0.895543\tAccuracy: 66.67%\n",
            "35\tValidation loss: 0.943884\tBest loss: 0.895543\tAccuracy: 64.67%\n",
            "36\tValidation loss: 0.939372\tBest loss: 0.895543\tAccuracy: 68.00%\n",
            "37\tValidation loss: 0.894239\tBest loss: 0.894239\tAccuracy: 67.33%\n",
            "38\tValidation loss: 0.888806\tBest loss: 0.888806\tAccuracy: 69.33%\n",
            "39\tValidation loss: 0.933829\tBest loss: 0.888806\tAccuracy: 66.00%\n",
            "40\tValidation loss: 0.911836\tBest loss: 0.888806\tAccuracy: 72.67%\n",
            "41\tValidation loss: 0.896729\tBest loss: 0.888806\tAccuracy: 70.00%\n",
            "42\tValidation loss: 0.929394\tBest loss: 0.888806\tAccuracy: 68.00%\n",
            "43\tValidation loss: 0.919418\tBest loss: 0.888806\tAccuracy: 69.33%\n",
            "44\tValidation loss: 0.907830\tBest loss: 0.888806\tAccuracy: 65.33%\n",
            "45\tValidation loss: 1.004304\tBest loss: 0.888806\tAccuracy: 71.33%\n",
            "46\tValidation loss: 0.871899\tBest loss: 0.871899\tAccuracy: 74.00%\n",
            "47\tValidation loss: 0.904889\tBest loss: 0.871899\tAccuracy: 67.33%\n",
            "48\tValidation loss: 0.914138\tBest loss: 0.871899\tAccuracy: 66.00%\n",
            "49\tValidation loss: 0.930001\tBest loss: 0.871899\tAccuracy: 69.33%\n",
            "50\tValidation loss: 0.962153\tBest loss: 0.871899\tAccuracy: 68.67%\n",
            "51\tValidation loss: 0.925021\tBest loss: 0.871899\tAccuracy: 65.33%\n",
            "52\tValidation loss: 0.974412\tBest loss: 0.871899\tAccuracy: 67.33%\n",
            "53\tValidation loss: 0.897499\tBest loss: 0.871899\tAccuracy: 68.67%\n",
            "54\tValidation loss: 0.933581\tBest loss: 0.871899\tAccuracy: 60.67%\n",
            "55\tValidation loss: 0.988574\tBest loss: 0.871899\tAccuracy: 68.67%\n",
            "56\tValidation loss: 0.927290\tBest loss: 0.871899\tAccuracy: 66.67%\n",
            "57\tValidation loss: 1.018713\tBest loss: 0.871899\tAccuracy: 64.00%\n",
            "58\tValidation loss: 0.964709\tBest loss: 0.871899\tAccuracy: 66.00%\n",
            "59\tValidation loss: 1.004696\tBest loss: 0.871899\tAccuracy: 59.33%\n",
            "60\tValidation loss: 1.008746\tBest loss: 0.871899\tAccuracy: 58.67%\n",
            "61\tValidation loss: 0.948558\tBest loss: 0.871899\tAccuracy: 68.00%\n",
            "62\tValidation loss: 0.966037\tBest loss: 0.871899\tAccuracy: 64.00%\n",
            "63\tValidation loss: 0.922541\tBest loss: 0.871899\tAccuracy: 68.00%\n",
            "64\tValidation loss: 0.892541\tBest loss: 0.871899\tAccuracy: 72.00%\n",
            "65\tValidation loss: 0.890340\tBest loss: 0.871899\tAccuracy: 70.67%\n",
            "66\tValidation loss: 0.957904\tBest loss: 0.871899\tAccuracy: 66.00%\n",
            "Early stopping!\n",
            "Total training time: 1.9s\n",
            "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n",
            "Final test accuracy: 64.02%\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "n_epochs = 1000\n",
        "batch_size = 20\n",
        "\n",
        "max_checks_without_progress = 20\n",
        "checks_without_progress = 0\n",
        "best_loss = np.infty\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    restore_saver.restore(sess, \"./my_best_mnist_model_0_to_4\")\n",
        "    t0 = time.time()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        rnd_idx = np.random.permutation(len(X_train2))\n",
        "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
        "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
        "        if loss_val < best_loss:\n",
        "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
        "            best_loss = loss_val\n",
        "            checks_without_progress = 0\n",
        "        else:\n",
        "            checks_without_progress += 1\n",
        "            if checks_without_progress > max_checks_without_progress:\n",
        "                print(\"Early stopping!\")\n",
        "                break\n",
        "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
        "            epoch, loss_val, best_loss, acc_val * 100))\n",
        "\n",
        "    t1 = time.time()\n",
        "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
        "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
        "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XlGUrR2fy7j"
      },
      "source": [
        "\n",
        "c.\tTry caching the frozen layers, and train the model again: how much faster is it now?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqySnHfify7k"
      },
      "outputs": [],
      "source": [
        "hidden5_out = tf.get_default_graph().get_tensor_by_name(\"hidden5_out:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMlAd1-ufy7l",
        "outputId": "c3f76b5c-efb2-4c9b-d574-70f946437741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./my_best_mnist_model_0_to_4\n",
            "0\tValidation loss: 1.416103\tBest loss: 1.416103\tAccuracy: 44.00%\n",
            "1\tValidation loss: 1.099216\tBest loss: 1.099216\tAccuracy: 53.33%\n",
            "2\tValidation loss: 1.024954\tBest loss: 1.024954\tAccuracy: 59.33%\n",
            "3\tValidation loss: 0.969193\tBest loss: 0.969193\tAccuracy: 60.00%\n",
            "4\tValidation loss: 0.973461\tBest loss: 0.969193\tAccuracy: 64.67%\n",
            "5\tValidation loss: 0.949333\tBest loss: 0.949333\tAccuracy: 64.67%\n",
            "6\tValidation loss: 0.922953\tBest loss: 0.922953\tAccuracy: 66.67%\n",
            "7\tValidation loss: 0.957186\tBest loss: 0.922953\tAccuracy: 62.67%\n",
            "8\tValidation loss: 0.950264\tBest loss: 0.922953\tAccuracy: 68.00%\n",
            "9\tValidation loss: 1.053465\tBest loss: 0.922953\tAccuracy: 59.33%\n",
            "10\tValidation loss: 1.069949\tBest loss: 0.922953\tAccuracy: 54.00%\n",
            "11\tValidation loss: 0.965197\tBest loss: 0.922953\tAccuracy: 62.67%\n",
            "12\tValidation loss: 0.949233\tBest loss: 0.922953\tAccuracy: 63.33%\n",
            "13\tValidation loss: 0.926229\tBest loss: 0.922953\tAccuracy: 63.33%\n",
            "14\tValidation loss: 0.922854\tBest loss: 0.922854\tAccuracy: 67.33%\n",
            "15\tValidation loss: 0.965205\tBest loss: 0.922854\tAccuracy: 66.67%\n",
            "16\tValidation loss: 1.050026\tBest loss: 0.922854\tAccuracy: 59.33%\n",
            "17\tValidation loss: 0.946699\tBest loss: 0.922854\tAccuracy: 64.67%\n",
            "18\tValidation loss: 0.973966\tBest loss: 0.922854\tAccuracy: 64.00%\n",
            "19\tValidation loss: 0.902573\tBest loss: 0.902573\tAccuracy: 66.67%\n",
            "20\tValidation loss: 0.933625\tBest loss: 0.902573\tAccuracy: 65.33%\n",
            "21\tValidation loss: 0.938296\tBest loss: 0.902573\tAccuracy: 64.00%\n",
            "22\tValidation loss: 0.938790\tBest loss: 0.902573\tAccuracy: 66.67%\n",
            "23\tValidation loss: 0.936572\tBest loss: 0.902573\tAccuracy: 68.00%\n",
            "24\tValidation loss: 1.039109\tBest loss: 0.902573\tAccuracy: 65.33%\n",
            "25\tValidation loss: 1.146837\tBest loss: 0.902573\tAccuracy: 59.33%\n",
            "26\tValidation loss: 0.958702\tBest loss: 0.902573\tAccuracy: 68.67%\n",
            "27\tValidation loss: 0.915434\tBest loss: 0.902573\tAccuracy: 70.67%\n",
            "28\tValidation loss: 0.915402\tBest loss: 0.902573\tAccuracy: 66.00%\n",
            "29\tValidation loss: 0.920591\tBest loss: 0.902573\tAccuracy: 70.67%\n",
            "30\tValidation loss: 1.029216\tBest loss: 0.902573\tAccuracy: 64.67%\n",
            "31\tValidation loss: 1.039922\tBest loss: 0.902573\tAccuracy: 55.33%\n",
            "32\tValidation loss: 0.925041\tBest loss: 0.902573\tAccuracy: 64.00%\n",
            "33\tValidation loss: 0.944033\tBest loss: 0.902573\tAccuracy: 67.33%\n",
            "34\tValidation loss: 0.941914\tBest loss: 0.902573\tAccuracy: 66.67%\n",
            "35\tValidation loss: 0.866297\tBest loss: 0.866297\tAccuracy: 69.33%\n",
            "36\tValidation loss: 0.900787\tBest loss: 0.866297\tAccuracy: 70.67%\n",
            "37\tValidation loss: 0.889670\tBest loss: 0.866297\tAccuracy: 66.67%\n",
            "38\tValidation loss: 0.968139\tBest loss: 0.866297\tAccuracy: 62.00%\n",
            "39\tValidation loss: 0.929764\tBest loss: 0.866297\tAccuracy: 66.00%\n",
            "40\tValidation loss: 0.889130\tBest loss: 0.866297\tAccuracy: 68.00%\n",
            "41\tValidation loss: 0.940024\tBest loss: 0.866297\tAccuracy: 70.00%\n",
            "42\tValidation loss: 0.896472\tBest loss: 0.866297\tAccuracy: 69.33%\n",
            "43\tValidation loss: 0.893887\tBest loss: 0.866297\tAccuracy: 67.33%\n",
            "44\tValidation loss: 0.925727\tBest loss: 0.866297\tAccuracy: 68.67%\n",
            "45\tValidation loss: 0.945748\tBest loss: 0.866297\tAccuracy: 66.00%\n",
            "46\tValidation loss: 0.897087\tBest loss: 0.866297\tAccuracy: 70.00%\n",
            "47\tValidation loss: 0.923855\tBest loss: 0.866297\tAccuracy: 68.67%\n",
            "48\tValidation loss: 0.944244\tBest loss: 0.866297\tAccuracy: 66.67%\n",
            "49\tValidation loss: 0.975582\tBest loss: 0.866297\tAccuracy: 66.67%\n",
            "50\tValidation loss: 0.889869\tBest loss: 0.866297\tAccuracy: 68.67%\n",
            "51\tValidation loss: 0.895552\tBest loss: 0.866297\tAccuracy: 69.33%\n",
            "52\tValidation loss: 0.943707\tBest loss: 0.866297\tAccuracy: 66.00%\n",
            "53\tValidation loss: 0.902883\tBest loss: 0.866297\tAccuracy: 70.67%\n",
            "54\tValidation loss: 0.958292\tBest loss: 0.866297\tAccuracy: 68.67%\n",
            "55\tValidation loss: 0.917368\tBest loss: 0.866297\tAccuracy: 67.33%\n",
            "Early stopping!\n",
            "Total training time: 1.1s\n",
            "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n",
            "Final test accuracy: 61.16%\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "n_epochs = 1000\n",
        "batch_size = 20\n",
        "\n",
        "max_checks_without_progress = 20\n",
        "checks_without_progress = 0\n",
        "best_loss = np.infty\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    restore_saver.restore(sess, \"./my_best_mnist_model_0_to_4\")\n",
        "    t0 = time.time()\n",
        "\n",
        "    hidden5_train = hidden5_out.eval(feed_dict={X: X_train2, y: y_train2})\n",
        "    hidden5_valid = hidden5_out.eval(feed_dict={X: X_valid2, y: y_valid2})\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        rnd_idx = np.random.permutation(len(X_train2))\n",
        "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
        "            h5_batch, y_batch = hidden5_train[rnd_indices], y_train2[rnd_indices]\n",
        "            sess.run(training_op, feed_dict={hidden5_out: h5_batch, y: y_batch})\n",
        "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={hidden5_out: hidden5_valid, y: y_valid2})\n",
        "        if loss_val < best_loss:\n",
        "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
        "            best_loss = loss_val\n",
        "            checks_without_progress = 0\n",
        "        else:\n",
        "            checks_without_progress += 1\n",
        "            if checks_without_progress > max_checks_without_progress:\n",
        "                print(\"Early stopping!\")\n",
        "                break\n",
        "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
        "            epoch, loss_val, best_loss, acc_val * 100))\n",
        "\n",
        "    t1 = time.time()\n",
        "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
        "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
        "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8lgFIeTfy7l"
      },
      "source": [
        "d.\tTry again reusing just four hidden layers instead of five. Can you achieve a higher precision?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBk0qNT_fy7n"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "n_outputs = 5\n",
        "\n",
        "restore_saver = tf.train.import_meta_graph(\"./my_best_mnist_model_0_to_4.meta\")\n",
        "\n",
        "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
        "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
        "\n",
        "hidden4_out = tf.get_default_graph().get_tensor_by_name(\"hidden4_out:0\")\n",
        "logits = tf.layers.dense(hidden4_out, n_outputs, kernel_initializer=he_init, name=\"new_logits\")\n",
        "Y_proba = tf.nn.softmax(logits)\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "loss = tf.reduce_mean(xentropy)\n",
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6poMsorofy7o"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"new_logits\")\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
        "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "four_frozen_saver = tf.train.Saver()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atNdOmqYfy7o",
        "outputId": "d96598ce-398d-40c7-c1ba-345dd69534a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./my_best_mnist_model_0_to_4\n",
            "0\tValidation loss: 1.073254\tBest loss: 1.073254\tAccuracy: 51.33%\n",
            "1\tValidation loss: 1.039487\tBest loss: 1.039487\tAccuracy: 64.00%\n",
            "2\tValidation loss: 0.991418\tBest loss: 0.991418\tAccuracy: 59.33%\n",
            "3\tValidation loss: 0.902691\tBest loss: 0.902691\tAccuracy: 64.67%\n",
            "4\tValidation loss: 0.919874\tBest loss: 0.902691\tAccuracy: 63.33%\n",
            "5\tValidation loss: 0.879734\tBest loss: 0.879734\tAccuracy: 72.00%\n",
            "6\tValidation loss: 0.877940\tBest loss: 0.877940\tAccuracy: 70.67%\n",
            "7\tValidation loss: 0.899513\tBest loss: 0.877940\tAccuracy: 71.33%\n",
            "8\tValidation loss: 0.879717\tBest loss: 0.877940\tAccuracy: 67.33%\n",
            "9\tValidation loss: 0.826527\tBest loss: 0.826527\tAccuracy: 75.33%\n",
            "10\tValidation loss: 0.890165\tBest loss: 0.826527\tAccuracy: 67.33%\n",
            "11\tValidation loss: 0.876235\tBest loss: 0.826527\tAccuracy: 68.67%\n",
            "12\tValidation loss: 0.877598\tBest loss: 0.826527\tAccuracy: 71.33%\n",
            "13\tValidation loss: 0.898070\tBest loss: 0.826527\tAccuracy: 74.67%\n",
            "14\tValidation loss: 0.923526\tBest loss: 0.826527\tAccuracy: 68.00%\n",
            "15\tValidation loss: 0.859624\tBest loss: 0.826527\tAccuracy: 70.00%\n",
            "16\tValidation loss: 0.896264\tBest loss: 0.826527\tAccuracy: 67.33%\n",
            "17\tValidation loss: 0.800813\tBest loss: 0.800813\tAccuracy: 73.33%\n",
            "18\tValidation loss: 0.811318\tBest loss: 0.800813\tAccuracy: 74.00%\n",
            "19\tValidation loss: 0.809687\tBest loss: 0.800813\tAccuracy: 75.33%\n",
            "20\tValidation loss: 0.807125\tBest loss: 0.800813\tAccuracy: 72.67%\n",
            "21\tValidation loss: 0.819150\tBest loss: 0.800813\tAccuracy: 71.33%\n",
            "22\tValidation loss: 0.849812\tBest loss: 0.800813\tAccuracy: 76.67%\n",
            "23\tValidation loss: 0.801709\tBest loss: 0.800813\tAccuracy: 74.67%\n",
            "24\tValidation loss: 0.832877\tBest loss: 0.800813\tAccuracy: 74.00%\n",
            "25\tValidation loss: 0.792853\tBest loss: 0.792853\tAccuracy: 72.67%\n",
            "26\tValidation loss: 0.842031\tBest loss: 0.792853\tAccuracy: 76.00%\n",
            "27\tValidation loss: 0.872236\tBest loss: 0.792853\tAccuracy: 71.33%\n",
            "28\tValidation loss: 0.782557\tBest loss: 0.782557\tAccuracy: 78.00%\n",
            "29\tValidation loss: 0.802515\tBest loss: 0.782557\tAccuracy: 73.33%\n",
            "30\tValidation loss: 0.812652\tBest loss: 0.782557\tAccuracy: 72.67%\n",
            "31\tValidation loss: 0.825467\tBest loss: 0.782557\tAccuracy: 76.00%\n",
            "32\tValidation loss: 0.791320\tBest loss: 0.782557\tAccuracy: 76.67%\n",
            "33\tValidation loss: 0.785207\tBest loss: 0.782557\tAccuracy: 77.33%\n",
            "34\tValidation loss: 0.815450\tBest loss: 0.782557\tAccuracy: 76.67%\n",
            "35\tValidation loss: 0.865081\tBest loss: 0.782557\tAccuracy: 71.33%\n",
            "36\tValidation loss: 0.852323\tBest loss: 0.782557\tAccuracy: 74.67%\n",
            "37\tValidation loss: 0.836967\tBest loss: 0.782557\tAccuracy: 72.00%\n",
            "38\tValidation loss: 0.807404\tBest loss: 0.782557\tAccuracy: 77.33%\n",
            "39\tValidation loss: 0.821566\tBest loss: 0.782557\tAccuracy: 75.33%\n",
            "40\tValidation loss: 0.817326\tBest loss: 0.782557\tAccuracy: 76.00%\n",
            "41\tValidation loss: 0.807987\tBest loss: 0.782557\tAccuracy: 70.67%\n",
            "42\tValidation loss: 0.838029\tBest loss: 0.782557\tAccuracy: 74.00%\n",
            "43\tValidation loss: 0.820425\tBest loss: 0.782557\tAccuracy: 76.00%\n",
            "44\tValidation loss: 0.785871\tBest loss: 0.782557\tAccuracy: 76.00%\n",
            "45\tValidation loss: 0.844337\tBest loss: 0.782557\tAccuracy: 78.67%\n",
            "46\tValidation loss: 0.764127\tBest loss: 0.764127\tAccuracy: 78.67%\n",
            "47\tValidation loss: 0.789726\tBest loss: 0.764127\tAccuracy: 77.33%\n",
            "48\tValidation loss: 0.839190\tBest loss: 0.764127\tAccuracy: 72.67%\n",
            "49\tValidation loss: 0.849353\tBest loss: 0.764127\tAccuracy: 75.33%\n",
            "50\tValidation loss: 0.869818\tBest loss: 0.764127\tAccuracy: 74.00%\n",
            "51\tValidation loss: 0.805526\tBest loss: 0.764127\tAccuracy: 76.67%\n",
            "52\tValidation loss: 0.850749\tBest loss: 0.764127\tAccuracy: 72.67%\n",
            "53\tValidation loss: 0.838693\tBest loss: 0.764127\tAccuracy: 71.33%\n",
            "54\tValidation loss: 0.791396\tBest loss: 0.764127\tAccuracy: 75.33%\n",
            "55\tValidation loss: 0.846888\tBest loss: 0.764127\tAccuracy: 76.00%\n",
            "56\tValidation loss: 0.826717\tBest loss: 0.764127\tAccuracy: 74.67%\n",
            "57\tValidation loss: 0.878286\tBest loss: 0.764127\tAccuracy: 70.67%\n",
            "58\tValidation loss: 0.878869\tBest loss: 0.764127\tAccuracy: 72.67%\n",
            "59\tValidation loss: 0.822241\tBest loss: 0.764127\tAccuracy: 72.67%\n",
            "60\tValidation loss: 0.864925\tBest loss: 0.764127\tAccuracy: 73.33%\n",
            "61\tValidation loss: 0.804545\tBest loss: 0.764127\tAccuracy: 73.33%\n",
            "62\tValidation loss: 0.891784\tBest loss: 0.764127\tAccuracy: 72.67%\n",
            "63\tValidation loss: 0.810186\tBest loss: 0.764127\tAccuracy: 74.00%\n",
            "64\tValidation loss: 0.810786\tBest loss: 0.764127\tAccuracy: 74.67%\n",
            "65\tValidation loss: 0.818044\tBest loss: 0.764127\tAccuracy: 74.00%\n",
            "66\tValidation loss: 0.853420\tBest loss: 0.764127\tAccuracy: 74.67%\n",
            "Early stopping!\n",
            "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_four_frozen\n",
            "Final test accuracy: 69.10%\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 1000\n",
        "batch_size = 20\n",
        "\n",
        "max_checks_without_progress = 20\n",
        "checks_without_progress = 0\n",
        "best_loss = np.infty\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    restore_saver.restore(sess, \"./my_best_mnist_model_0_to_4\")\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        rnd_idx = np.random.permutation(len(X_train2))\n",
        "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
        "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
        "        if loss_val < best_loss:\n",
        "            save_path = four_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_four_frozen\")\n",
        "            best_loss = loss_val\n",
        "            checks_without_progress = 0\n",
        "        else:\n",
        "            checks_without_progress += 1\n",
        "            if checks_without_progress > max_checks_without_progress:\n",
        "                print(\"Early stopping!\")\n",
        "                break\n",
        "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
        "            epoch, loss_val, best_loss, acc_val * 100))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    four_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_four_frozen\")\n",
        "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
        "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLQeEHkPfy7p"
      },
      "source": [
        "e.\tNow unfreeze the top two hidden layers and continue training: can you get the model to perform even better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut2t99fRfy7q"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "unfrozen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"hidden[34]|new_logits\")\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam3\")\n",
        "training_op = optimizer.minimize(loss, var_list=unfrozen_vars)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "two_frozen_saver = tf.train.Saver()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dM4x6fdfy7r",
        "outputId": "256cb622-541b-43bf-fe3d-30ba1abcc405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_four_frozen\n",
            "0\tValidation loss: 1.054859\tBest loss: 1.054859\tAccuracy: 74.00%\n",
            "1\tValidation loss: 0.812410\tBest loss: 0.812410\tAccuracy: 78.00%\n",
            "2\tValidation loss: 0.750377\tBest loss: 0.750377\tAccuracy: 80.67%\n",
            "3\tValidation loss: 0.570973\tBest loss: 0.570973\tAccuracy: 84.67%\n",
            "4\tValidation loss: 0.805442\tBest loss: 0.570973\tAccuracy: 79.33%\n",
            "5\tValidation loss: 0.920925\tBest loss: 0.570973\tAccuracy: 80.00%\n",
            "6\tValidation loss: 0.817471\tBest loss: 0.570973\tAccuracy: 81.33%\n",
            "7\tValidation loss: 0.777876\tBest loss: 0.570973\tAccuracy: 84.00%\n",
            "8\tValidation loss: 1.030498\tBest loss: 0.570973\tAccuracy: 74.67%\n",
            "9\tValidation loss: 1.074356\tBest loss: 0.570973\tAccuracy: 81.33%\n",
            "10\tValidation loss: 0.912521\tBest loss: 0.570973\tAccuracy: 83.33%\n",
            "11\tValidation loss: 1.356695\tBest loss: 0.570973\tAccuracy: 79.33%\n",
            "12\tValidation loss: 0.918798\tBest loss: 0.570973\tAccuracy: 82.00%\n",
            "13\tValidation loss: 0.971029\tBest loss: 0.570973\tAccuracy: 82.67%\n",
            "14\tValidation loss: 0.860108\tBest loss: 0.570973\tAccuracy: 83.33%\n",
            "15\tValidation loss: 1.074813\tBest loss: 0.570973\tAccuracy: 82.00%\n",
            "16\tValidation loss: 0.867760\tBest loss: 0.570973\tAccuracy: 84.00%\n",
            "17\tValidation loss: 0.858290\tBest loss: 0.570973\tAccuracy: 85.33%\n",
            "18\tValidation loss: 0.996560\tBest loss: 0.570973\tAccuracy: 85.33%\n",
            "19\tValidation loss: 1.304507\tBest loss: 0.570973\tAccuracy: 83.33%\n",
            "20\tValidation loss: 1.134808\tBest loss: 0.570973\tAccuracy: 80.67%\n",
            "21\tValidation loss: 1.189581\tBest loss: 0.570973\tAccuracy: 82.00%\n",
            "22\tValidation loss: 1.131344\tBest loss: 0.570973\tAccuracy: 81.33%\n",
            "23\tValidation loss: 1.240507\tBest loss: 0.570973\tAccuracy: 82.67%\n",
            "Early stopping!\n",
            "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_two_frozen\n",
            "Final test accuracy: 78.09%\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 1000\n",
        "batch_size = 20\n",
        "\n",
        "max_checks_without_progress = 20\n",
        "checks_without_progress = 0\n",
        "best_loss = np.infty\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    four_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_four_frozen\")\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        rnd_idx = np.random.permutation(len(X_train2))\n",
        "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
        "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
        "        if loss_val < best_loss:\n",
        "            save_path = two_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_two_frozen\")\n",
        "            best_loss = loss_val\n",
        "            checks_without_progress = 0\n",
        "        else:\n",
        "            checks_without_progress += 1\n",
        "            if checks_without_progress > max_checks_without_progress:\n",
        "                print(\"Early stopping!\")\n",
        "                break\n",
        "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
        "            epoch, loss_val, best_loss, acc_val * 100))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    two_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_two_frozen\")\n",
        "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
        "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZ5IoxSJfy7s"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam4\")\n",
        "training_op = optimizer.minimize(loss)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "no_frozen_saver = tf.train.Saver()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDUqi0RIfy7s",
        "outputId": "5e81d635-ce9f-4634-ab1f-c8fa18e8fddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_two_frozen\n",
            "0\tValidation loss: 0.863416\tBest loss: 0.863416\tAccuracy: 86.00%\n",
            "1\tValidation loss: 0.695079\tBest loss: 0.695079\tAccuracy: 90.00%\n",
            "2\tValidation loss: 0.402921\tBest loss: 0.402921\tAccuracy: 92.00%\n",
            "3\tValidation loss: 0.606936\tBest loss: 0.402921\tAccuracy: 92.00%\n",
            "4\tValidation loss: 0.354645\tBest loss: 0.354645\tAccuracy: 90.67%\n",
            "5\tValidation loss: 0.376935\tBest loss: 0.354645\tAccuracy: 90.67%\n",
            "6\tValidation loss: 0.593208\tBest loss: 0.354645\tAccuracy: 90.00%\n",
            "7\tValidation loss: 0.388302\tBest loss: 0.354645\tAccuracy: 92.67%\n",
            "8\tValidation loss: 0.503276\tBest loss: 0.354645\tAccuracy: 91.33%\n",
            "9\tValidation loss: 1.440716\tBest loss: 0.354645\tAccuracy: 80.00%\n",
            "10\tValidation loss: 0.464323\tBest loss: 0.354645\tAccuracy: 92.00%\n",
            "11\tValidation loss: 0.410302\tBest loss: 0.354645\tAccuracy: 93.33%\n",
            "12\tValidation loss: 1.131754\tBest loss: 0.354645\tAccuracy: 88.00%\n",
            "13\tValidation loss: 0.511544\tBest loss: 0.354645\tAccuracy: 92.00%\n",
            "14\tValidation loss: 0.402083\tBest loss: 0.354645\tAccuracy: 94.00%\n",
            "15\tValidation loss: 1.149943\tBest loss: 0.354645\tAccuracy: 92.00%\n",
            "16\tValidation loss: 0.405171\tBest loss: 0.354645\tAccuracy: 94.00%\n",
            "17\tValidation loss: 0.304346\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "18\tValidation loss: 0.386952\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "19\tValidation loss: 0.387063\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "20\tValidation loss: 0.384417\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "21\tValidation loss: 0.381116\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "22\tValidation loss: 0.379346\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "23\tValidation loss: 0.378128\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "24\tValidation loss: 0.376642\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "25\tValidation loss: 0.375432\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "26\tValidation loss: 0.374804\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "27\tValidation loss: 0.373952\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "28\tValidation loss: 0.373471\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "29\tValidation loss: 0.373027\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "30\tValidation loss: 0.373124\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "31\tValidation loss: 0.373098\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "32\tValidation loss: 0.373206\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "33\tValidation loss: 0.372812\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "34\tValidation loss: 0.373109\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "35\tValidation loss: 0.372616\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "36\tValidation loss: 0.372491\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "37\tValidation loss: 0.372270\tBest loss: 0.304346\tAccuracy: 94.67%\n",
            "Early stopping!\n",
            "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_no_frozen\n",
            "Final test accuracy: 91.34%\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 1000\n",
        "batch_size = 20\n",
        "\n",
        "max_checks_without_progress = 20\n",
        "checks_without_progress = 0\n",
        "best_loss = np.infty\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    two_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_two_frozen\")\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        rnd_idx = np.random.permutation(len(X_train2))\n",
        "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
        "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
        "        if loss_val < best_loss:\n",
        "            save_path = no_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_no_frozen\")\n",
        "            best_loss = loss_val\n",
        "            checks_without_progress = 0\n",
        "        else:\n",
        "            checks_without_progress += 1\n",
        "            if checks_without_progress > max_checks_without_progress:\n",
        "                print(\"Early stopping!\")\n",
        "                break\n",
        "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
        "            epoch, loss_val, best_loss, acc_val * 100))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    no_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_no_frozen\")\n",
        "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
        "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXTWceBEfy7t",
        "outputId": "5361ca96-68f4-4945-b060-2dd3278c4668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\tValidation loss: 0.674618\tBest loss: 0.674618\tAccuracy: 80.67%\n",
            "1\tValidation loss: 0.584845\tBest loss: 0.584845\tAccuracy: 88.67%\n",
            "2\tValidation loss: 0.647296\tBest loss: 0.584845\tAccuracy: 84.00%\n",
            "3\tValidation loss: 0.530389\tBest loss: 0.530389\tAccuracy: 87.33%\n",
            "4\tValidation loss: 0.683215\tBest loss: 0.530389\tAccuracy: 90.67%\n",
            "5\tValidation loss: 0.538040\tBest loss: 0.530389\tAccuracy: 89.33%\n",
            "6\tValidation loss: 0.670196\tBest loss: 0.530389\tAccuracy: 90.67%\n",
            "7\tValidation loss: 0.836470\tBest loss: 0.530389\tAccuracy: 85.33%\n",
            "8\tValidation loss: 0.837684\tBest loss: 0.530389\tAccuracy: 92.67%\n",
            "9\tValidation loss: 0.588950\tBest loss: 0.530389\tAccuracy: 88.00%\n",
            "10\tValidation loss: 0.643213\tBest loss: 0.530389\tAccuracy: 90.67%\n",
            "11\tValidation loss: 1.010521\tBest loss: 0.530389\tAccuracy: 88.00%\n",
            "12\tValidation loss: 0.931423\tBest loss: 0.530389\tAccuracy: 90.00%\n",
            "13\tValidation loss: 1.563524\tBest loss: 0.530389\tAccuracy: 88.67%\n",
            "14\tValidation loss: 2.340119\tBest loss: 0.530389\tAccuracy: 89.33%\n",
            "15\tValidation loss: 1.402095\tBest loss: 0.530389\tAccuracy: 88.00%\n",
            "16\tValidation loss: 1.269974\tBest loss: 0.530389\tAccuracy: 86.00%\n",
            "17\tValidation loss: 1.036325\tBest loss: 0.530389\tAccuracy: 89.33%\n",
            "18\tValidation loss: 1.578565\tBest loss: 0.530389\tAccuracy: 88.67%\n",
            "19\tValidation loss: 0.993890\tBest loss: 0.530389\tAccuracy: 93.33%\n",
            "20\tValidation loss: 0.958130\tBest loss: 0.530389\tAccuracy: 87.33%\n",
            "21\tValidation loss: 1.505322\tBest loss: 0.530389\tAccuracy: 88.67%\n",
            "22\tValidation loss: 1.378772\tBest loss: 0.530389\tAccuracy: 89.33%\n",
            "23\tValidation loss: 0.999445\tBest loss: 0.530389\tAccuracy: 88.00%\n",
            "24\tValidation loss: 2.366345\tBest loss: 0.530389\tAccuracy: 90.00%\n",
            "Early stopping!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DNNClassifier(activation=<function elu at 0x1243639d8>,\n",
              "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
              "       initializer=<tensorflow.python.ops.init_ops.VarianceScaling object at 0x117bf5828>,\n",
              "       learning_rate=0.01, n_hidden_layers=4, n_neurons=100,\n",
              "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
              "       random_state=42)"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dnn_clf_5_to_9 = DNNClassifier(n_hidden_layers=4, random_state=42)\n",
        "dnn_clf_5_to_9.fit(X_train2, y_train2, n_epochs=1000, X_valid=X_valid2, y_valid=y_valid2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqgjjKlEfy7t",
        "outputId": "39116064-ee31-444e-adef-fcd4ddc4c67f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8481793869574161"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = dnn_clf_5_to_9.predict(X_test2)\n",
        "accuracy_score(y_test2, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1yaqfmPfy7u"
      },
      "source": [
        "## 10. Pretraining on an auxiliary task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KarhuK7vfy7v"
      },
      "source": [
        "a.\tIn this exercise you will build a DNN that compares two MNIST digit images and predicts whether they represent the same digit or not. Then you will reuse the lower layers of this network to train an MNIST classifier using very little training data. Start by building two DNNs (let’s call them DNN A and B), both similar to the one you built earlier but without the output layer: each DNN should have five hidden layers of 100 neurons each, He initialization, and ELU activation. Next, add one more hidden layer with 10 units on top of both DNNs. To do this, you should use a keras.layers. Concatenate layer to con‐ catenate the outputs of both DNNs for each instance, then feed the result to the hidden layer. Finally, add an output layer with a single neuron using the logistic activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af6u_tiofy7w"
      },
      "outputs": [],
      "source": [
        "n_inputs = 28 * 28 # MNIST\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, 2, n_inputs), name=\"X\")\n",
        "X1, X2 = tf.unstack(X, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqgBj6bQfy7w"
      },
      "outputs": [],
      "source": [
        "y = tf.placeholder(tf.int32, shape=[None, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJvGs8zGfy7x"
      },
      "outputs": [],
      "source": [
        "dnn1 = dnn(X1, name=\"DNN_A\")\n",
        "dnn2 = dnn(X2, name=\"DNN_B\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1okcqsTfy7y"
      },
      "outputs": [],
      "source": [
        "dnn_outputs = tf.concat([dnn1, dnn2], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nl28zlnTfy7z",
        "outputId": "31148567-9cdb-459e-ed4e-da1e8389acb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(100)])"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dnn1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wfFyrtpfy7z",
        "outputId": "199a9419-44b7-471f-ab5b-cc218cb78dc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(100)])"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dnn2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnSxRxVTfy70",
        "outputId": "f817cda6-2aa2-4c9b-faed-3211e99c0c59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(200)])"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dnn_outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11z5RmVOfy70"
      },
      "outputs": [],
      "source": [
        "hidden = tf.layers.dense(dnn_outputs, units=10, activation=tf.nn.elu, kernel_initializer=he_init)\n",
        "logits = tf.layers.dense(hidden, units=1, kernel_initializer=he_init)\n",
        "y_proba = tf.nn.sigmoid(logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-gKOAuRfy71"
      },
      "outputs": [],
      "source": [
        "y_pred = tf.cast(tf.greater_equal(logits, 0), tf.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-OYKxZ3fy72"
      },
      "outputs": [],
      "source": [
        "y_as_float = tf.cast(y, tf.float32)\n",
        "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_as_float, logits=logits)\n",
        "loss = tf.reduce_mean(xentropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0masi8Sfy73"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "momentum = 0.95\n",
        "\n",
        "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
        "training_op = optimizer.minimize(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXB0WFucfy74"
      },
      "outputs": [],
      "source": [
        "y_pred_correct = tf.equal(y_pred, y)\n",
        "accuracy = tf.reduce_mean(tf.cast(y_pred_correct, tf.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnDBxOJafy75"
      },
      "outputs": [],
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5bYn9fefy75"
      },
      "source": [
        "b.\tSplit the MNIST training set in two sets: split #1 should containing 55,000 images, and split #2 should contain 5,000 images. Create a function that generates a training batch where each instance is a pair of MNIST images picked from split #1. Half of the training instances should be pairs of images that belong to the same class, while the other half should be images from different classes. For each pair, the training label should be 0 if the images are from the same class, or 1 if they are from different classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Mh61WZZfy76"
      },
      "outputs": [],
      "source": [
        "X_train1 = X_train\n",
        "y_train1 = y_train\n",
        "\n",
        "X_train2 = X_valid\n",
        "y_train2 = y_valid\n",
        "\n",
        "X_test = X_test\n",
        "y_test = y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpa0F_eKfy7_"
      },
      "outputs": [],
      "source": [
        "def generate_batch(images, labels, batch_size):\n",
        "    size1 = batch_size // 2\n",
        "    size2 = batch_size - size1\n",
        "    if size1 != size2 and np.random.rand() > 0.5:\n",
        "        size1, size2 = size2, size1\n",
        "    X = []\n",
        "    y = []\n",
        "    while len(X) < size1:\n",
        "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
        "        if rnd_idx1 != rnd_idx2 and labels[rnd_idx1] == labels[rnd_idx2]:\n",
        "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
        "            y.append([1])\n",
        "    while len(X) < batch_size:\n",
        "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
        "        if labels[rnd_idx1] != labels[rnd_idx2]:\n",
        "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
        "            y.append([0])\n",
        "    rnd_indices = np.random.permutation(batch_size)\n",
        "    return np.array(X)[rnd_indices], np.array(y)[rnd_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adCuZFREfy8A"
      },
      "outputs": [],
      "source": [
        "batch_size = 5\n",
        "X_batch, y_batch = generate_batch(X_train1, y_train1, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frCbWC8zfy8B",
        "outputId": "04f1f7a4-f9fb-465b-a905-037271bdef30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((5, 2, 784), dtype('float32'))"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_batch.shape, X_batch.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UrBM3qefy8C",
        "outputId": "7d275545-a619-49c3-dd80-acd40ae53d83"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(3, 3 * batch_size))\n",
        "plt.subplot(121)\n",
        "plt.imshow(X_batch[:,0].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
        "plt.axis('off')\n",
        "plt.subplot(122)\n",
        "plt.imshow(X_batch[:,1].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZOrq2Eqfy8D",
        "outputId": "5eb5e342-d69b-4fe2-fd5c-6abf3b074337"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqPLw74cfy8D"
      },
      "source": [
        "c.\tTrain the DNN on this training set. For each image pair, you can simultaneously feed the first image to DNN A and the second image to DNN B. The whole network will gradually learn to tell whether two images belong to the same class or not.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-ajulOFfy8E"
      },
      "outputs": [],
      "source": [
        "X_test1, y_test1 = generate_batch(X_test, y_test, batch_size=len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9vJa5dmfy8E",
        "outputId": "66e4778d-9cb2-4411-dae6-70b265638c08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Train loss: 0.69103277\n",
            "0 Test accuracy: 0.542\n",
            "1 Train loss: 0.6035354\n",
            "2 Train loss: 0.54946035\n",
            "3 Train loss: 0.47047246\n",
            "4 Train loss: 0.4060757\n",
            "5 Train loss: 0.38308156\n",
            "5 Test accuracy: 0.824\n",
            "6 Train loss: 0.39047274\n",
            "7 Train loss: 0.3390794\n",
            "8 Train loss: 0.3210671\n",
            "9 Train loss: 0.31792685\n",
            "10 Train loss: 0.24494292\n",
            "10 Test accuracy: 0.8881\n",
            "11 Train loss: 0.2929235\n",
            "12 Train loss: 0.23225449\n",
            "13 Train loss: 0.23180929\n",
            "14 Train loss: 0.19877923\n",
            "15 Train loss: 0.20065464\n",
            "15 Test accuracy: 0.9203\n",
            "16 Train loss: 0.19700499\n",
            "17 Train loss: 0.18893136\n",
            "18 Train loss: 0.19965452\n",
            "19 Train loss: 0.24071647\n",
            "20 Train loss: 0.18882024\n",
            "20 Test accuracy: 0.9367\n",
            "21 Train loss: 0.12419197\n",
            "22 Train loss: 0.14013417\n",
            "23 Train loss: 0.120789476\n",
            "24 Train loss: 0.15721135\n",
            "25 Train loss: 0.11507861\n",
            "25 Test accuracy: 0.948\n",
            "26 Train loss: 0.13891116\n",
            "27 Train loss: 0.1526081\n",
            "28 Train loss: 0.123436704\n",
            "<<50 more lines>>\n",
            "70 Test accuracy: 0.9743\n",
            "71 Train loss: 0.019732744\n",
            "72 Train loss: 0.039464083\n",
            "73 Train loss: 0.04187814\n",
            "74 Train loss: 0.05303406\n",
            "75 Train loss: 0.052625064\n",
            "75 Test accuracy: 0.9756\n",
            "76 Train loss: 0.038283084\n",
            "77 Train loss: 0.026332883\n",
            "78 Train loss: 0.07060841\n",
            "79 Train loss: 0.03239444\n",
            "80 Train loss: 0.03136283\n",
            "80 Test accuracy: 0.9731\n",
            "81 Train loss: 0.04390848\n",
            "82 Train loss: 0.015268046\n",
            "83 Train loss: 0.04875638\n",
            "84 Train loss: 0.029360933\n",
            "85 Train loss: 0.0418443\n",
            "85 Test accuracy: 0.9759\n",
            "86 Train loss: 0.018274888\n",
            "87 Train loss: 0.038872603\n",
            "88 Train loss: 0.02969683\n",
            "89 Train loss: 0.020990817\n",
            "90 Train loss: 0.045234833\n",
            "90 Test accuracy: 0.9769\n",
            "91 Train loss: 0.039237432\n",
            "92 Train loss: 0.031329047\n",
            "93 Train loss: 0.033414133\n",
            "94 Train loss: 0.025883088\n",
            "95 Train loss: 0.019567214\n",
            "95 Test accuracy: 0.9765\n",
            "96 Train loss: 0.020650322\n",
            "97 Train loss: 0.0339851\n",
            "98 Train loss: 0.047079965\n",
            "99 Train loss: 0.03125228\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 100\n",
        "batch_size = 500\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(len(X_train1) // batch_size):\n",
        "            X_batch, y_batch = generate_batch(X_train1, y_train1, batch_size)\n",
        "            loss_val, _ = sess.run([loss, training_op], feed_dict={X: X_batch, y: y_batch})\n",
        "        print(epoch, \"Train loss:\", loss_val)\n",
        "        if epoch % 5 == 0:\n",
        "            acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
        "            print(epoch, \"Test accuracy:\", acc_test)\n",
        "\n",
        "    save_path = saver.save(sess, \"./my_digit_comparison_model.ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxsIikhFfy8F"
      },
      "source": [
        "d.\tNow create a new DNN by reusing and freezing the hidden layers of DNN A and adding a softmax output layer on top with 10 neurons. Train this network on split #2 and see if you can achieve high performance despite having only 500 images per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XerXdYUUfy8G"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 * 28  # MNIST\n",
        "n_outputs = 10\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
        "\n",
        "dnn_outputs = dnn(X, name=\"DNN_A\")\n",
        "frozen_outputs = tf.stop_gradient(dnn_outputs)\n",
        "\n",
        "logits = tf.layers.dense(frozen_outputs, n_outputs, kernel_initializer=he_init)\n",
        "Y_proba = tf.nn.softmax(logits)\n",
        "\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "\n",
        "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
        "training_op = optimizer.minimize(loss)\n",
        "\n",
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "dnn_A_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"DNN_A\")\n",
        "restore_saver = tf.train.Saver(var_list={var.op.name: var for var in dnn_A_vars})\n",
        "saver = tf.train.Saver()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akn_KwMpfy8H",
        "outputId": "3e7bae85-cde4-4efd-fed9-4a037b5519af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./my_digit_comparison_model.ckpt\n",
            "0 Test accuracy: 0.9455\n",
            "10 Test accuracy: 0.9634\n",
            "20 Test accuracy: 0.9659\n",
            "30 Test accuracy: 0.9656\n",
            "40 Test accuracy: 0.9655\n",
            "50 Test accuracy: 0.9656\n",
            "60 Test accuracy: 0.9655\n",
            "70 Test accuracy: 0.9656\n",
            "80 Test accuracy: 0.9654\n",
            "90 Test accuracy: 0.9654\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 100\n",
        "batch_size = 50\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    restore_saver.restore(sess, \"./my_digit_comparison_model.ckpt\")\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        rnd_idx = np.random.permutation(len(X_train2))\n",
        "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
        "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        if epoch % 10 == 0:\n",
        "            acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "            print(epoch, \"Test accuracy:\", acc_test)\n",
        "\n",
        "    save_path = saver.save(sess, \"./my_mnist_model_final.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OeQn2HXfy8I"
      },
      "outputs": [],
      "source": [
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 * 28  # MNIST\n",
        "n_outputs = 10\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
        "\n",
        "dnn_outputs = dnn(X, name=\"DNN_A\")\n",
        "\n",
        "logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init)\n",
        "Y_proba = tf.nn.softmax(logits)\n",
        "\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "\n",
        "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
        "training_op = optimizer.minimize(loss)\n",
        "\n",
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "dnn_A_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"DNN_A\")\n",
        "restore_saver = tf.train.Saver(var_list={var.op.name: var for var in dnn_A_vars})\n",
        "saver = tf.train.Saver()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-4EvTJNfy8J",
        "outputId": "0345cadf-3ac8-40da-c063-24f368dda9dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Test accuracy: 0.8694\n",
            "10 Test accuracy: 0.9276\n",
            "20 Test accuracy: 0.9299\n",
            "30 Test accuracy: 0.935\n",
            "40 Test accuracy: 0.942\n",
            "50 Test accuracy: 0.9435\n",
            "60 Test accuracy: 0.9442\n",
            "70 Test accuracy: 0.9447\n",
            "80 Test accuracy: 0.9448\n",
            "90 Test accuracy: 0.945\n",
            "100 Test accuracy: 0.945\n",
            "110 Test accuracy: 0.9458\n",
            "120 Test accuracy: 0.9456\n",
            "130 Test accuracy: 0.9458\n",
            "140 Test accuracy: 0.9458\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 150\n",
        "batch_size = 50\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        rnd_idx = np.random.permutation(len(X_train2))\n",
        "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
        "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        if epoch % 10 == 0:\n",
        "            acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "            print(epoch, \"Test accuracy:\", acc_test)\n",
        "\n",
        "    save_path = saver.save(sess, \"./my_mnist_model_final.ckpt\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "nav_menu": {
      "height": "360px",
      "width": "416px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}